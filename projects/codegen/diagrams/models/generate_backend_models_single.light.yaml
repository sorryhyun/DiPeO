# Backend Single Node Generation from TypeScript - Simplified version
# Generates Pydantic model and static node from TypeScript specifications

version: light

nodes:
  # Start node
  - label: Start
    type: start
    position: {x: 50, y: 100}

  # Parse batch input to get node type 
  - label: Parse Node Type
    type: code_job
    position: {x: 200, y: 100}
    props:
      language: python
      code: |
        # In batch mode, input comes directly as node_spec_path
        # It can be a string or in a dict under 'node_spec_path' key
        if 'node_spec_path' in locals():
            node_type = node_spec_path
        elif 'default' in locals():
            # Sometimes wrapped in default
            if isinstance(default, dict):
                node_type = default.get('node_spec_path', 'unknown')
            else:
                node_type = default
        else:
            # Try to find it in all available variables
            all_vars = {**globals(), **locals()}
            node_type = all_vars.get('node_spec_path', 'unknown')
        
        # node_type is like "api-job", "person-job", etc.
        result = node_type
  
  # Load cached AST data for this node spec
  - label: Load Cached AST
    type: db
    position: {x: 350, y: 100}
    props:
      operation: read
      sub_type: file
      source_details: temp/specifications/nodes/{node_type}.spec.ts.json
      format: json
      
  # Load codegen mappings
  - label: Load Codegen Mappings
    type: db
    position: {x: 350, y: 200}
    props:
      operation: read
      sub_type: file
      source_details: temp/codegen/mappings.ts.json
      format: json
      
  # Extract mappings
  - label: Extract Mappings
    type: code_job
    position: {x: 500, y: 200}
    props:
      language: python
      filePath: projects/codegen/code/shared/extract_mappings.py
      functionName: main
      
  # Extract specification from AST
  - label: Extract Specification
    type: code_job
    position: {x: 500, y: 100}
    props:
      language: python
      filePath: projects/codegen/code/shared/typescript_spec_parser.py
      functionName: main
      
  # Prepare complete context for templates
  - label: Prepare Context
    type: code_job
    position: {x: 700, y: 150}
    props:
      language: python
      code: |
        # Access labeled inputs from the inputs dictionary
        spec_result = inputs.get('spec_data', {})
        mappings = inputs.get('mappings', {})
        node_type_str = inputs.get('node_type', 'unknown')
        
        # Extract the actual spec data (typescript_spec_parser returns {"spec_data": spec})
        if isinstance(spec_result, dict) and 'spec_data' in spec_result:
            spec_data = spec_result['spec_data']
        else:
            spec_data = spec_result
        
        # Clean up nodeType by removing "NodeType." prefix and convert to lowercase
        cleaned_spec_data = dict(spec_data)
        if 'nodeType' in cleaned_spec_data:
            node_type_raw = cleaned_spec_data['nodeType']
            # Remove "NodeType." prefix if present
            if node_type_raw.startswith('NodeType.'):
                node_type_enum = node_type_raw.replace('NodeType.', '')
            else:
                node_type_enum = node_type_raw
            # Convert UPPER_SNAKE_CASE to lower_snake_case for filters to work properly
            cleaned_spec_data['nodeType'] = node_type_enum.lower()
        
        # Convert node type from hyphenated to snake_case for file names
        # e.g., "api-job" -> "api_job"
        node_type_snake = node_type_str.replace('-', '_')
        
        # Create node_name in PascalCase for class names
        node_name = ''.join(word.title() for word in node_type_snake.split('_'))
        
        # Build the context with everything needed for templates
        context = {
            **cleaned_spec_data,  # All spec fields with cleaned nodeType
            'mappings': mappings,  # Type mappings for python_type_with_context filter
            'node_type': node_type_snake,  # For file names (api_job)
            'node_name': node_name,  # For class names (ApiJob)
            'node_naming': {  # Keep for backward compatibility with templates
                'node_type': node_type_snake,
                'node_name': node_name
            }
        }
        
        print(f"Generating {node_name} ({node_type_snake})")
        result = context

  # Generate backend code using template_job nodes
  - label: Generate Pydantic Model
    type: template_job
    position: {x: 900, y: 100}
    props:
      engine: jinja2
      template_path: projects/codegen/templates/backend/pydantic_single_model.j2
      output_path: dipeo/diagram_generated_staged/models/{{ node_type }}_model.py

  - label: Generate Static Node
    type: template_job
    position: {x: 900, y: 200}
    props:
      engine: jinja2
      template_path: projects/codegen/templates/backend/static_nodes.j2
      output_path: dipeo/diagram_generated_staged/nodes/{{ node_type }}_node.py

connections:
  # Parse input first
  - {from: Start, to: Parse Node Type}
    
  # Load resources in parallel
  - {from: Parse Node Type, to: Load Cached AST, label: node_type, content_type: object}
  - {from: Parse Node Type, to: Load Codegen Mappings}
    
  # Extract specification from AST
  - {from: Load Cached AST, to: Extract Specification, label: ast_data}
  - {from: Parse Node Type, to: Extract Specification, label: node_type}
    
  # Extract mappings
  - {from: Load Codegen Mappings, to: Extract Mappings, content_type: object}
    
  # Prepare context with all data
  - {from: Extract Specification, to: Prepare Context, label: spec_data, content_type: object}
  - {from: Extract Mappings, to: Prepare Context, label: mappings, content_type: object}
  - {from: Parse Node Type, to: Prepare Context, label: node_type}
  
  # Pass context to template_job nodes
  - {from: Prepare Context, to: Generate Pydantic Model, content_type: object}
  - {from: Prepare Context, to: Generate Static Node, content_type: object}