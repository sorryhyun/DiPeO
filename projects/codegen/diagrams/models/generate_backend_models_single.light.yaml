# Backend Single Node Generation from TypeScript - Simplified version
# Generates Pydantic model and static node from TypeScript specifications

version: light

nodes:
  # Start node
  - label: Start
    type: start
    position: {x: 50, y: 100}
    props:
      trigger_mode: none

  # Parse batch input to get node type
  - label: Parse Node Type
    type: code_job
    position: {x: 200, y: 100}
    props:
      language: python
      code: |
        # node_type is like "api-job", "person-job", etc.
        # Extract just the string value for template substitution
        result = default['default']['node_spec_path']

  # Load cached AST data for this node spec
  - label: Load Cached AST
    type: db
    position: {x: 350, y: 100}
    props:
      operation: read
      sub_type: file
      file: temp/nodes/{node_type}.spec.ts.json
      format: json

  # Load specific mapping constants directly using keys
  - label: Load Codegen Mappings
    type: db
    position: {x: 350, y: 200}
    props:
      operation: read
      sub_type: file
      file: temp/codegen/mappings.ts.json
      format: json
      keys: ["constants"]

  # Extract specification from AST
  - label: Extract Specification
    type: code_job
    position: {x: 500, y: 100}
    props:
      language: python
      file_path: dipeo/infrastructure/codegen/generators/spec_parser.py
      function_name: main

  # Prepare complete context for templates
  - label: Prepare Context
    type: code_job
    position: {x: 700, y: 150}
    props:
      language: python
      code: |
        # Access labeled inputs from the inputs dictionary
        spec_result = inputs.get('spec_data', {})
        raw_mappings = inputs.get('mappings', {})
        node_type_str = inputs.get('node_type', 'unknown')

        # Process raw constants into mappings format (like extract_mappings.py would do)
        mappings = {}
        if 'constants' in raw_mappings:
            # Map TypeScript constant names to our mapping keys
            mapping_name_map = {
                'NODE_INTERFACE_MAP': 'node_interface_map',
                'TS_TO_PY_TYPE': 'ts_to_py_type',
                'TYPE_TO_FIELD': 'type_to_field',
                'TYPE_TO_ZOD': 'type_to_zod',
                'BRANDED_TYPES': 'branded_types',
                'BASE_FIELDS': 'base_fields',
                'FIELD_SPECIAL_HANDLING': 'field_special_handling'
            }

            for constant in raw_mappings.get('constants', []):
                var_name = constant.get('name', '')
                value = constant.get('value', {})

                if var_name in mapping_name_map:
                    mapping_key = mapping_name_map[var_name]

                    # Clean up the values - remove extra quotes from keys AND values
                    if isinstance(value, dict):
                        cleaned_value = {}
                        for k, v in value.items():
                            # Remove surrounding quotes from key
                            if k.startswith("'") and k.endswith("'"):
                                clean_key = k[1:-1]
                            elif k.startswith('"') and k.endswith('"'):
                                clean_key = k[1:-1]
                            else:
                                clean_key = k.strip().strip("'\"")
                            # Also clean the value if it's a string with quotes
                            clean_value = v.strip().strip("'\"") if isinstance(v, str) else v
                            cleaned_value[clean_key] = clean_value
                        mappings[mapping_key] = cleaned_value
                    elif isinstance(value, list):
                        mappings[mapping_key] = value
                    else:
                        mappings[mapping_key] = value

        # Extract the actual spec data (typescript_spec_parser returns {"spec_data": spec})
        if isinstance(spec_result, dict) and 'spec_data' in spec_result:
            spec_data = spec_result['spec_data']
        else:
            spec_data = spec_result

        # Clean up nodeType by removing "NodeType." prefix and convert to lowercase
        # Ensure spec_data is a dictionary
        if not isinstance(spec_data, dict):
            raise ValueError(f"spec_data is not a dictionary: {type(spec_data)} - {spec_data}")

        cleaned_spec_data = dict(spec_data)
        if 'nodeType' in cleaned_spec_data:
            node_type_raw = cleaned_spec_data['nodeType']
            # Remove "NodeType." prefix if present
            if node_type_raw.startswith('NodeType.'):
                node_type_enum = node_type_raw.replace('NodeType.', '')
            else:
                node_type_enum = node_type_raw
            # Convert UPPER_SNAKE_CASE to lower_snake_case for filters to work properly
            cleaned_spec_data['nodeType'] = node_type_enum.lower()

        # Convert displayName from camelCase to snake_case for template
        if 'displayName' in cleaned_spec_data:
            cleaned_spec_data['display_name'] = cleaned_spec_data['displayName']

        # Also keep 'description' and 'category' as-is (they're already lowercase in specs)
        # But ensure they have snake_case aliases too just in case
        if 'description' in cleaned_spec_data:
            cleaned_spec_data['description'] = cleaned_spec_data.get('description', '')
        if 'category' in cleaned_spec_data:
            cleaned_spec_data['category'] = cleaned_spec_data.get('category', '')

        # Convert node type from hyphenated to snake_case for file names
        # e.g., "api-job" -> "api_job"
        node_type_snake = node_type_str.replace('-', '_')

        # Create node_name in PascalCase for class names
        node_name = ''.join(word.title() for word in node_type_snake.split('_'))

        # Create additional naming variants for templates
        node_type_upper = node_type_snake.upper()  # API_JOB
        handler_class_name = f"{node_name}Handler"  # ApiJobHandler
        data_model_name = f"{node_name}Node"  # ApiJobNode

        # Extract handler metadata if present in spec, or use defaults
        handler_metadata = cleaned_spec_data.get('handlerMetadata', {})
        if not handler_metadata:
            # Provide sensible defaults based on node type
            handler_metadata = {
                'serviceKeys': [],
                'mixins': [],
                'customImports': []
            }

        # Extract timeout if present
        timeout = cleaned_spec_data.get('timeout', None)

        # Build the context with everything needed for templates
        try:
            context = {
                **cleaned_spec_data,  # All spec fields with cleaned nodeType
                'mappings': mappings,  # Type mappings for python_type_with_context filter
                'node_type': node_type_snake,  # For file names (api_job)
                'node_name': node_name,  # For class names (ApiJob)
                'node_type_upper': node_type_upper,  # For enums (API_JOB)
                'handler_class_name': handler_class_name,  # For handler class (ApiJobHandler)
                'data_model_name': data_model_name,  # For data model (ApiJobNode)
                'handler_metadata': handler_metadata,  # Handler configuration
                'timeout': timeout,  # Timeout value if set
                'node_naming': {  # Keep for backward compatibility with templates
                    'node_type': node_type_snake,
                    'node_name': node_name
                }
            }
        except Exception as e:
            raise ValueError(
                f"Failed to build context for node {node_type_str}. "
                f"cleaned_spec_data type: {type(cleaned_spec_data)}, "
                f"mappings type: {type(mappings)}. "
                f"Error: {str(e)}"
            )

        result = context

  - label: Generate Unified Model
    type: template_job
    position: {x: 900, y: 300}
    props:
      engine: jinja2
      template_path: projects/codegen/templates/backend/unified_node_model.j2
      output_path: dipeo/diagram_generated_staged/unified_nodes/{{ node_type }}_node.py

#  - label: Generate handler stub
#    type: template_job
#    position: {x: 900, y: 300}
#    props:
#      engine: jinja2
#      template_path: projects/codegen/templates/models/handler_stub.j2
#      output_path: dipeo/diagram_generated_staged/handlers/{{ node_type }}_node.py

  # End node to complete the diagram
  - label: End
    type: endpoint
    position: {x: 1100, y: 200}
    props:
      save_to_file: false

connections:
  # Parse input first
  - {from: Start, to: Parse Node Type, content_type: object}

  # Load resources in parallel (node_type passed as text for template substitution)
  - {from: Parse Node Type, to: Load Cached AST, label: node_type}
  - {from: Parse Node Type, to: Load Codegen Mappings}

  # Extract specification from AST
  - {from: Load Cached AST, to: Extract Specification, label: ast_data, content_type: object}
  - {from: Parse Node Type, to: Extract Specification, label: node_type}

  # Prepare context with all data
  - {from: Extract Specification, to: Prepare Context, label: spec_data, content_type: object}
  - {from: Load Codegen Mappings, to: Prepare Context, label: mappings, content_type: object}
  - {from: Parse Node Type, to: Prepare Context, label: node_type}

  # Pass context to template_job nodes
  - {from: Prepare Context, to: Generate Unified Model, content_type: object}
#  - {from: Prepare Context, to: Generate handler stub, content_type: object}
#  - {from: Generate handler stub, to: End}
  - {from: Generate Unified Model, to: End}
