"""
Auto-generated static node types from domain models.
DO NOT EDIT THIS FILE DIRECTLY.
Generated at: 2025-08-22T16:10:36.997620
Generated by: domain model static nodes generation
"""


from dataclasses import *
from typing import *

from .domain_models import *
from .enums import *
from .integrations import *


def _to_enum(value: Optional[str], enum_class) -> Optional[Any]:
    """Convert string value to enum instance if not None."""
    if value is None:
        return None
    if isinstance(value, enum_class):
        return value
    return enum_class(value)


@dataclass(frozen=True)
class BaseExecutableNode:
    """Base class for all executable node types."""
    # Required fields only - no defaults in base class
    id: NodeID
    position: Vec2
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        result = {
            "id": self.id,
            "position": {"x": self.position.x, "y": self.position.y}
        }
        # Subclasses should extend this
        return result


# Debug: Show all available variables
# Available variables: now: 2025-08-22T16:10:36.997620
# static_nodes_data exists: yes
# static_nodes_data type: dict
# static_nodes_data keys: ['node_classes', 'enum_fields', 'now']
# Number of classes: 14

@dataclass(frozen=True)
class ApiJobNode(BaseExecutableNode):
    # Required node-specific fields
    url: str = field()
    method: HttpMethod = field()
    headers: Optional[Dict[str, str]] = field()
    params: Optional[JsonDict] = field()
    body: Optional[JsonValue] = field()
    timeout: Optional[int] = field()
    auth_type: Optional[AuthType] = field()
    auth_config: Optional[Dict[str, str]] = field()
    # Type field with default
    type: NodeType = field(default=NodeType.API_JOB, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["url"] = self.url
        data["method"] = self.method
        data["headers"] = self.headers
        data["params"] = self.params
        data["body"] = self.body
        data["timeout"] = self.timeout
        data["auth_type"] = self.auth_type
        data["auth_config"] = self.auth_config
        return data



@dataclass(frozen=True)
class CodeJobNode(BaseExecutableNode):
    # Required node-specific fields
    language: SupportedLanguage = field()
    filePath: Optional[str] = field()
    code: Optional[str] = field()
    functionName: Optional[str] = field()
    timeout: Optional[int] = field()
    # Type field with default
    type: NodeType = field(default=NodeType.CODE_JOB, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["language"] = self.language
        data["filePath"] = self.filePath
        data["code"] = self.code
        data["functionName"] = self.functionName
        data["timeout"] = self.timeout
        return data



@dataclass(frozen=True)
class ConditionNode(BaseExecutableNode):
    # Required node-specific fields
    expression: Optional[str] = field()
    node_indices: Optional[List[str]] = field()
    expose_index_as: Optional[str] = field()
    # Type field with default
    type: NodeType = field(default=NodeType.CONDITION, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None
    # Optional node-specific fields
    condition_type: Optional[ConditionType] = "custom"

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["condition_type"] = self.condition_type
        data["expression"] = self.expression
        data["node_indices"] = self.node_indices
        data["expose_index_as"] = self.expose_index_as
        return data



@dataclass(frozen=True)
class DBNode(BaseExecutableNode):
    # Required node-specific fields
    file: Optional[List[Union[str, str]]] = field()
    collection: Optional[str] = field()
    sub_type: DBBlockSubType = field()
    operation: str = field()
    query: Optional[str] = field()
    data: Optional[JsonDict] = field()
    glob: Optional[bool] = field()
    # Type field with default
    type: NodeType = field(default=NodeType.DB, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None
    # Optional node-specific fields
    serialize_json: Optional[bool] = False
    format: Optional[str] = "json"

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["file"] = self.file
        data["collection"] = self.collection
        data["sub_type"] = self.sub_type
        data["operation"] = self.operation
        data["query"] = self.query
        data["data"] = self.data
        data["serialize_json"] = self.serialize_json
        data["glob"] = self.glob
        data["format"] = self.format
        return data



@dataclass(frozen=True)
class EndpointNode(BaseExecutableNode):
    # Required node-specific fields
    save_to_file: bool = field()
    file_name: Optional[str] = field()
    # Type field with default
    type: NodeType = field(default=NodeType.ENDPOINT, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["save_to_file"] = self.save_to_file
        data["file_name"] = self.file_name
        return data



@dataclass(frozen=True)
class HookNode(BaseExecutableNode):
    # Required node-specific fields
    command: Optional[str] = field()
    args: Optional[List[str]] = field()
    env: Optional[Dict[str, str]] = field()
    cwd: Optional[str] = field()
    url: Optional[str] = field()
    method: Optional[HttpMethod] = field()
    headers: Optional[Dict[str, str]] = field()
    script: Optional[str] = field()
    function_name: Optional[str] = field()
    file_path: Optional[str] = field()
    format: Optional[Literal["json", "yaml", "text"]] = field()
    retry_delay: Optional[int] = field()
    # Type field with default
    type: NodeType = field(default=NodeType.HOOK, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None
    # Optional node-specific fields
    hook_type: HookType = "shell"
    timeout: Optional[int] = 60
    retry_count: Optional[int] = 0

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["hook_type"] = self.hook_type
        data["command"] = self.command
        data["args"] = self.args
        data["env"] = self.env
        data["cwd"] = self.cwd
        data["url"] = self.url
        data["method"] = self.method
        data["headers"] = self.headers
        data["script"] = self.script
        data["function_name"] = self.function_name
        data["file_path"] = self.file_path
        data["format"] = self.format
        data["timeout"] = self.timeout
        data["retry_count"] = self.retry_count
        data["retry_delay"] = self.retry_delay
        return data



@dataclass(frozen=True)
class IntegratedApiNode(BaseExecutableNode):
    # Required node-specific fields
    provider: str = field()
    operation: str = field()
    config: Optional[JsonDict] = field()
    resource_id: Optional[str] = field()
    timeout: Optional[int] = field()
    max_retries: Optional[int] = field()
    # Type field with default
    type: NodeType = field(default=NodeType.INTEGRATED_API, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["provider"] = self.provider
        data["operation"] = self.operation
        data["config"] = self.config
        data["resource_id"] = self.resource_id
        data["timeout"] = self.timeout
        data["max_retries"] = self.max_retries
        return data



@dataclass(frozen=True)
class JsonSchemaValidatorNode(BaseExecutableNode):
    # Required node-specific fields
    schema_path: Optional[str] = field()
    json_schema: Optional[JsonDict] = field()
    data_path: Optional[str] = field()
    strict_mode: Optional[bool] = field()
    error_on_extra: Optional[bool] = field()
    # Type field with default
    type: NodeType = field(default=NodeType.JSON_SCHEMA_VALIDATOR, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["schema_path"] = self.schema_path
        data["json_schema"] = self.json_schema
        data["data_path"] = self.data_path
        data["strict_mode"] = self.strict_mode
        data["error_on_extra"] = self.error_on_extra
        return data



@dataclass(frozen=True)
class PersonJobNode(BaseExecutableNode):
    # Required node-specific fields
    person: Optional[PersonID] = field()
    first_only_prompt: str = field()
    first_prompt_file: Optional[str] = field()
    default_prompt: Optional[str] = field()
    prompt_file: Optional[str] = field()
    memorize_to: str = field()
    at_most: int = field()
    text_format: Optional[str] = field()
    text_format_file: Optional[str] = field()
    batch: Optional[bool] = field()
    batch_input_key: Optional[str] = field()
    batch_parallel: Optional[bool] = field()
    max_concurrent: Optional[int] = field()
    # Type field with default
    type: NodeType = field(default=NodeType.PERSON_JOB, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None
    # Optional node-specific fields
    max_iteration: int = 100
    tools: Optional[ToolSelection] = "none"

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["person"] = self.person
        data["first_only_prompt"] = self.first_only_prompt
        data["first_prompt_file"] = self.first_prompt_file
        data["default_prompt"] = self.default_prompt
        data["prompt_file"] = self.prompt_file
        data["max_iteration"] = self.max_iteration
        data["memorize_to"] = self.memorize_to
        data["at_most"] = self.at_most
        data["tools"] = self.tools
        data["text_format"] = self.text_format
        data["text_format_file"] = self.text_format_file
        data["batch"] = self.batch
        data["batch_input_key"] = self.batch_input_key
        data["batch_parallel"] = self.batch_parallel
        data["max_concurrent"] = self.max_concurrent
        return data



@dataclass(frozen=True)
class StartNode(BaseExecutableNode):
    # Required node-specific fields
    custom_data: Optional[Dict[str, Union[str, float, bool]]] = field()
    output_data_structure: Optional[Dict[str, str]] = field()
    hook_event: Optional[str] = field()
    hook_filters: Optional[JsonDict] = field()
    # Type field with default
    type: NodeType = field(default=NodeType.START, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None
    # Optional node-specific fields
    trigger_mode: HookTriggerMode = "none"

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["trigger_mode"] = self.trigger_mode
        data["custom_data"] = self.custom_data
        data["output_data_structure"] = self.output_data_structure
        data["hook_event"] = self.hook_event
        data["hook_filters"] = self.hook_filters
        return data



@dataclass(frozen=True)
class SubDiagramNode(BaseExecutableNode):
    # Required node-specific fields
    diagram_name: Optional[str] = field()
    diagram_format: Optional[DiagramFormat] = field()
    diagram_data: Optional[JsonDict] = field()
    batch_input_key: Optional[str] = field()
    # Type field with default
    type: NodeType = field(default=NodeType.SUB_DIAGRAM, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None
    # Optional node-specific fields
    batch: Optional[bool] = False
    batch_parallel: Optional[bool] = False
    ignoreIfSub: Optional[bool] = False

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["diagram_name"] = self.diagram_name
        data["diagram_format"] = self.diagram_format
        data["diagram_data"] = self.diagram_data
        data["batch"] = self.batch
        data["batch_input_key"] = self.batch_input_key
        data["batch_parallel"] = self.batch_parallel
        data["ignoreIfSub"] = self.ignoreIfSub
        return data



@dataclass(frozen=True)
class TemplateJobNode(BaseExecutableNode):
    # Required node-specific fields
    template_path: Optional[str] = field()
    template_content: Optional[str] = field()
    output_path: Optional[str] = field()
    variables: Optional[JsonDict] = field()
    foreach: Optional[Dict[str, Any]] = field()
    preprocessor: Optional[TemplatePreprocessor] = field()
    # Type field with default
    type: NodeType = field(default=NodeType.TEMPLATE_JOB, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None
    # Optional node-specific fields
    engine: Optional[TemplateEngine] = "jinja2"

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["template_path"] = self.template_path
        data["template_content"] = self.template_content
        data["output_path"] = self.output_path
        data["variables"] = self.variables
        data["engine"] = self.engine
        data["foreach"] = self.foreach
        data["preprocessor"] = self.preprocessor
        return data



@dataclass(frozen=True)
class TypescriptAstNode(BaseExecutableNode):
    # Required node-specific fields
    source: Optional[str] = field()
    batch: Optional[bool] = field()
    sources: Optional[Dict[str, str]] = field()
    batchInputKey: Optional[str] = field()
    # Type field with default
    type: NodeType = field(default=NodeType.TYPESCRIPT_AST, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None
    # Optional node-specific fields
    extractPatterns: Optional[List[str]] = field(default_factory=lambda: ['interface', 'type', 'enum'])
    includeJSDoc: Optional[bool] = False
    parseMode: Optional[Literal["module", "script"]] = "module"

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["source"] = self.source
        data["extractPatterns"] = self.extractPatterns
        data["includeJSDoc"] = self.includeJSDoc
        data["parseMode"] = self.parseMode
        data["batch"] = self.batch
        data["sources"] = self.sources
        data["batchInputKey"] = self.batchInputKey
        return data



@dataclass(frozen=True)
class UserResponseNode(BaseExecutableNode):
    # Required node-specific fields
    prompt: str = field()
    # Type field with default
    type: NodeType = field(default=NodeType.USER_RESPONSE, init=False)
    # Base optional fields
    label: str = ""
    flipped: bool = False
    metadata: Optional[Dict[str, Any]] = None
    # Optional node-specific fields
    timeout: int = 300

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation."""
        data = super().to_dict()
        data["type"] = self.type.value
        data["label"] = self.label
        data["flipped"] = self.flipped
        if self.metadata:
            data["metadata"] = self.metadata
        data["prompt"] = self.prompt
        data["timeout"] = self.timeout
        return data



@dataclass(frozen=True)
class PersonBatchJobNode(PersonJobNode):
    """Person batch job node - same as PersonJobNode but with different type."""
    type: NodeType = field(default=NodeType.PERSON_BATCH_JOB, init=False)


ExecutableNode = Union[
    ApiJobNode,
    CodeJobNode,
    ConditionNode,
    DBNode,
    EndpointNode,
    HookNode,
    IntegratedApiNode,
    JsonSchemaValidatorNode,
    PersonJobNode,
    StartNode,
    SubDiagramNode,
    TemplateJobNode,
    TypescriptAstNode,
    UserResponseNode,
    PersonBatchJobNode
]


def create_executable_node(
    node_type: NodeType,
    node_id: NodeID,
    position: Vec2,
    label: str = "",
    data: Optional[Dict[str, Any]] = None,
    flipped: bool = False,
    metadata: Optional[Dict[str, Any]] = None
) -> ExecutableNode:
    """Factory function to create typed executable nodes from diagram data."""
    data = data or {}

    if node_type == NodeType.API_JOB:
        return ApiJobNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            url=data.get("url"),
            method=data.get("method"),
            headers=data.get("headers"),
            params=data.get("params"),
            body=data.get("body"),
            timeout=data.get("timeout"),
            auth_type=data.get("auth_type"),
            auth_config=data.get("auth_config"),
        )
    

    if node_type == NodeType.CODE_JOB:
        return CodeJobNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            language=data.get("language"),
            filePath=data.get("filePath"),
            code=data.get("code"),
            functionName=data.get("functionName"),
            timeout=data.get("timeout"),
        )
    

    if node_type == NodeType.CONDITION:
        return ConditionNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            condition_type=data.get("condition_type", "custom"),
            expression=data.get("expression"),
            node_indices=data.get("node_indices"),
            expose_index_as=data.get("expose_index_as"),
        )
    

    if node_type == NodeType.DB:
        return DBNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            file=data.get("file"),
            collection=data.get("collection"),
            sub_type=data.get("sub_type"),
            operation=data.get("operation"),
            query=data.get("query"),
            data=data.get("data"),
            serialize_json=data.get("serialize_json", False),
            glob=data.get("glob"),
            format=data.get("format", "json"),
        )
    

    if node_type == NodeType.ENDPOINT:
        return EndpointNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            save_to_file=data.get("save_to_file"),
            file_name=data.get("file_name"),
        )
    

    if node_type == NodeType.HOOK:
        return HookNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            hook_type=data.get("hook_type", "shell"),
            command=data.get("command"),
            args=data.get("args"),
            env=data.get("env"),
            cwd=data.get("cwd"),
            url=data.get("url"),
            method=data.get("method"),
            headers=data.get("headers"),
            script=data.get("script"),
            function_name=data.get("function_name"),
            file_path=data.get("file_path"),
            format=data.get("format"),
            timeout=data.get("timeout", 60),
            retry_count=data.get("retry_count", 0),
            retry_delay=data.get("retry_delay"),
        )
    

    if node_type == NodeType.INTEGRATED_API:
        return IntegratedApiNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            provider=data.get("provider"),
            operation=data.get("operation"),
            config=data.get("config"),
            resource_id=data.get("resource_id"),
            timeout=data.get("timeout"),
            max_retries=data.get("max_retries"),
        )
    

    if node_type == NodeType.JSON_SCHEMA_VALIDATOR:
        return JsonSchemaValidatorNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            schema_path=data.get("schema_path"),
            json_schema=data.get("json_schema"),
            data_path=data.get("data_path"),
            strict_mode=data.get("strict_mode"),
            error_on_extra=data.get("error_on_extra"),
        )
    

    if node_type == NodeType.PERSON_JOB:
        return PersonJobNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            person=data.get("person"),
            first_only_prompt=data.get("first_only_prompt"),
            first_prompt_file=data.get("first_prompt_file"),
            default_prompt=data.get("default_prompt"),
            prompt_file=data.get("prompt_file"),
            max_iteration=data.get("max_iteration", 100),
            memorize_to=data.get("memorize_to"),
            at_most=data.get("at_most"),
            tools=data.get("tools", "none"),
            text_format=data.get("text_format"),
            text_format_file=data.get("text_format_file"),
            batch=data.get("batch"),
            batch_input_key=data.get("batch_input_key"),
            batch_parallel=data.get("batch_parallel"),
            max_concurrent=data.get("max_concurrent"),
        )
    

    if node_type == NodeType.START:
        return StartNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            trigger_mode=data.get("trigger_mode", "none"),
            custom_data=data.get("custom_data"),
            output_data_structure=data.get("output_data_structure"),
            hook_event=data.get("hook_event"),
            hook_filters=data.get("hook_filters"),
        )
    

    if node_type == NodeType.SUB_DIAGRAM:
        return SubDiagramNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            diagram_name=data.get("diagram_name"),
            diagram_format=data.get("diagram_format"),
            diagram_data=data.get("diagram_data"),
            batch=data.get("batch", False),
            batch_input_key=data.get("batch_input_key"),
            batch_parallel=data.get("batch_parallel", False),
            ignoreIfSub=data.get("ignoreIfSub", False),
        )
    

    if node_type == NodeType.TEMPLATE_JOB:
        return TemplateJobNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            template_path=data.get("template_path"),
            template_content=data.get("template_content"),
            output_path=data.get("output_path"),
            variables=data.get("variables"),
            engine=data.get("engine", "jinja2"),
            foreach=data.get("foreach"),
            preprocessor=data.get("preprocessor"),
        )
    

    if node_type == NodeType.TYPESCRIPT_AST:
        return TypescriptAstNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            source=data.get("source"),
            extractPatterns=data.get("extractPatterns"),
            includeJSDoc=data.get("includeJSDoc", False),
            parseMode=data.get("parseMode", "module"),
            batch=data.get("batch"),
            sources=data.get("sources"),
            batchInputKey=data.get("batchInputKey"),
        )
    

    if node_type == NodeType.USER_RESPONSE:
        return UserResponseNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            prompt=data.get("prompt"),
            timeout=data.get("timeout", 300),
        )
    

    if node_type == NodeType.PERSON_BATCH_JOB:
        return PersonBatchJobNode(
            id=node_id,
            position=position,
            label=label,
            flipped=flipped,
            metadata=metadata,
            person=data.get("person"),
            first_only_prompt=data.get("first_only_prompt"),
            first_prompt_file=data.get("first_prompt_file"),
            default_prompt=data.get("default_prompt"),
            prompt_file=data.get("prompt_file"),
            max_iteration=data.get("max_iteration", 100),
            memorize_to=data.get("memorize_to"),
            at_most=data.get("at_most"),
            tools=data.get("tools", "none"),
            text_format=data.get("text_format"),
            text_format_file=data.get("text_format_file"),
            batch=data.get("batch"),
            batch_input_key=data.get("batch_input_key"),
            batch_parallel=data.get("batch_parallel"),
            max_concurrent=data.get("max_concurrent"),
        )
    
    raise ValueError(f"Unknown node type: {node_type}")