# Auto-generated from JSON Schema
# DO NOT EDIT MANUALLY

# generated by datamodel-codegen:
#   filename:  condition.schema.json
#   timestamp: 2025-09-06T03:56:11+00:00

from __future__ import annotations

from enum import Enum
from typing import List, Literal, Optional

from pydantic import BaseModel, ConfigDict, Field, RootModel


class ConditionType(Enum):
    """
    Condition type: detect_max_iterations, nodes_executed, custom, or llm_decision
    """

    check_nodes_executed = 'check_nodes_executed'
    custom = 'custom'
    detect_max_iterations = 'detect_max_iterations'
    llm_decision = 'llm_decision'


class PersonID(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    field__brand: Literal['PersonID'] = Field(..., alias='__brand')


class ConditionNodeData(BaseModel):
    """
    Configuration data for Condition nodes that handle conditional branching
    """

    model_config = ConfigDict(
        extra='forbid',
    )
    at_most: float | None = Field(None, description='Max messages to keep in memory')
    condition_type: ConditionType | None = Field(
        None,
        description='Condition type: detect_max_iterations, nodes_executed, custom, or llm_decision',
    )
    expose_index_as: str | None = Field(
        None,
        description="Variable name to expose the condition node's execution count (0-based index) to downstream nodes",
    )
    expression: str | None = Field(
        None, description='Python expression for custom type (access to all variables)'
    )
    flipped: bool | None = None
    judge_by: str | None = Field(
        None, description='The prompt/criteria for LLM to judge'
    )
    judge_by_file: str | None = Field(
        None, description='External prompt file in {subdirectory}/prompts/'
    )
    label: str
    memorize_to: str | None = Field(
        None, description='Memory control (e.g., "GOLDFISH" for fresh evaluation)'
    )
    node_indices: list[str] | None = Field(
        None, description='List of node indices for nodes_executed condition type'
    )
    person: PersonID | None = Field(
        None, description='AI agent to use (when condition_type is LLM_DECISION)'
    )
    skippable: bool | None = Field(
        None,
        description="When true, downstream nodes can execute even if this condition hasn't been evaluated yet",
    )


class Model(RootModel[ConditionNodeData]):
    root: ConditionNodeData
