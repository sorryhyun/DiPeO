# Auto-generated from JSON Schema
# DO NOT EDIT MANUALLY

# generated by datamodel-codegen:
#   filename:  personbatchjob.schema.json
#   timestamp: 2025-09-07T09:54:37+00:00

from __future__ import annotations

from enum import Enum
from typing import Literal, Optional

from pydantic import BaseModel, ConfigDict, Field, RootModel


class PersonID(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
    )
    field__brand: Literal['PersonID'] = Field(..., alias='__brand')


class Tools(Enum):
    """
    LLM tools to enable (web_search_preview, etc.)
    """

    image = 'image'
    none = 'none'
    websearch = 'websearch'


class PersonBatchJobNodeData(BaseModel):
    """
    Configuration data for PersonJob nodes that execute LLM agents
    """

    model_config = ConfigDict(
        extra='forbid',
    )
    at_most: float
    batch: Optional[bool] = Field(
        None, description='Enable batch processing for arrays'
    )
    batch_input_key: Optional[str] = Field(
        None, description='Array variable name for batch processing'
    )
    batch_parallel: Optional[bool] = Field(
        None, description='Execute batch items in parallel'
    )
    default_prompt: Optional[str] = Field(
        None,
        description='Prompt template using {{variable}} syntax for subsequent iterations',
    )
    first_only_prompt: str = Field(
        ...,
        description='Special prompt for first iteration only, supports {{variable}} syntax',
    )
    first_prompt_file: Optional[str] = Field(
        None,
        description='External prompt file for first iteration only (overrides first_only_prompt)',
    )
    flipped: Optional[bool] = None
    label: str
    max_concurrent: Optional[float] = Field(
        None, description='Maximum concurrent batch executions'
    )
    max_iteration: float = Field(
        ..., description='Maximum conversation turns (default: 1)'
    )
    memorize_to: str
    person: Optional[PersonID] = Field(
        None, description="Reference to agent defined in 'persons' section"
    )
    prompt_file: Optional[str] = Field(
        None,
        description='External prompt file in files/prompts/ (overrides inline prompts)',
    )
    text_format: Optional[str] = Field(
        None, description='Pydantic model name for structured output'
    )
    text_format_file: Optional[str] = Field(
        None,
        description='External Python file with Pydantic models (overrides text_format)',
    )
    tools: Optional[Tools] = Field(
        None, description='LLM tools to enable (web_search_preview, etc.)'
    )


class Model(RootModel[PersonBatchJobNodeData]):
    root: PersonBatchJobNodeData
