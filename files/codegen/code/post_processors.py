"""
Post-processing functions for generated code.
These functions are applied after template rendering to clean up and format the output.
"""

import re
from typing import Dict, Any
from datetime import datetime


def main(inputs: Dict[str, Any]) -> Dict[str, Any]:
    """Main entry point - provides information about available functions."""
    return {
        "message": "DiPeO Code Post-Processors",
        "available_functions": [
            "sort_graphql_definitions",
            "add_generated_header",
            "validate_and_fix_imports",
            "remove_duplicate_lines",
            "fix_typescript_types",
            "format_python_docstrings"
        ],
        "description": "Post-processing functions for generated code"
    }


def sort_graphql_definitions(inputs: Dict[str, Any]) -> str:
    """
    Sort GraphQL type definitions alphabetically while preserving structure.
    
    Inputs:
        content: GraphQL schema content to sort
    """
    content = inputs.get('content', inputs.get('default', ''))
    
    # Parse GraphQL definitions
    definition_pattern = r'(type|input|enum|interface|union|scalar)\s+(\w+)[^{]*\{[^}]*\}'
    definitions = []
    
    # Extract all top-level definitions
    for match in re.finditer(definition_pattern, content, re.MULTILINE | re.DOTALL):
        def_type = match.group(1)
        def_name = match.group(2)
        def_content = match.group(0)
        definitions.append((def_type, def_name, def_content))
    
    # Sort by type first, then by name
    type_order = ['scalar', 'enum', 'interface', 'type', 'input', 'union']
    definitions.sort(key=lambda x: (type_order.index(x[0]) if x[0] in type_order else 99, x[1]))
    
    # Reconstruct the schema
    sorted_definitions = []
    for _, _, def_content in definitions:
        sorted_definitions.append(def_content)
    
    # Preserve any header comments and schema definitions
    header_match = re.match(r'^(#[^\n]*\n)*', content)
    header = header_match.group(0) if header_match else ''
    
    # Check for schema definition
    schema_match = re.search(r'schema\s*\{[^}]*\}', content, re.MULTILINE | re.DOTALL)
    schema_def = schema_match.group(0) if schema_match else ''
    
    # Combine everything
    result = header
    if sorted_definitions:
        result += '\n'.join(sorted_definitions)
    if schema_def:
        result += '\n\n' + schema_def
    
    return result.strip() + '\n'


def add_generated_header(inputs: Dict[str, Any]) -> str:
    """
    Add a header comment to generated files.
    
    Inputs:
        content: File content
        file_type: Type of file (python, typescript, graphql, etc.)
        source: Source specification file
    """
    content = inputs.get('content', inputs.get('default', ''))
    file_type = inputs.get('file_type', 'unknown')
    source = inputs.get('source', 'unknown')
    
    # Determine comment style based on file type
    comment_styles = {
        'python': ('#', '#', '#'),
        'typescript': ('//', '//', '//'),
        'javascript': ('//', '//', '//'),
        'graphql': ('#', '#', '#'),
        'yaml': ('#', '#', '#'),
        'sql': ('--', '--', '--')
    }
    
    start, middle, end = comment_styles.get(file_type, ('#', '#', '#'))
    
    timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')
    
    header = f"""{start} AUTO-GENERATED FILE - DO NOT EDIT
{middle} Generated by DiPeO Code Generation System
{middle} Generated at: {timestamp}
{middle} Source: {source}
{end}

"""
    
    return header + content


def validate_and_fix_imports(inputs: Dict[str, Any]) -> str:
    """
    Validate and fix import statements in TypeScript/JavaScript files.
    
    Inputs:
        content: File content
        base_path: Base path for relative imports
    """
    content = inputs.get('content', inputs.get('default', ''))
    base_path = inputs.get('base_path', '@')
    
    # Fix deep relative imports (../../../) with path aliases
    def fix_deep_imports(match):
        import_path = match.group(2)
        depth = import_path.count('../')
        
        if depth >= 3:
            # Convert to absolute import
            path_parts = import_path.split('/')
            clean_path = '/'.join(p for p in path_parts if p != '..')
            return f"{match.group(1)}{base_path}/{clean_path}{match.group(3)}"
        return match.group(0)
    
    # Pattern for import statements
    import_pattern = r'(import\s+.*?from\s+[\'"])([\.\/]+[^\'"]*)([\'"];?)'
    content = re.sub(import_pattern, fix_deep_imports, content)
    
    # Remove duplicate imports
    seen_imports = set()
    lines = content.split('\n')
    cleaned_lines = []
    
    for line in lines:
        if line.strip().startswith('import'):
            if line in seen_imports:
                continue
            seen_imports.add(line)
        cleaned_lines.append(line)
    
    return '\n'.join(cleaned_lines)


def remove_duplicate_lines(inputs: Dict[str, Any]) -> str:
    """
    Remove duplicate consecutive lines from generated content.
    
    Inputs:
        content: File content
        preserve_empty: Whether to preserve empty lines (default: True)
    """
    content = inputs.get('content', inputs.get('default', ''))
    preserve_empty = inputs.get('preserve_empty', True)
    
    lines = content.split('\n')
    result = []
    prev_line = None
    
    for line in lines:
        if preserve_empty and not line.strip():
            result.append(line)
        elif line != prev_line:
            result.append(line)
            prev_line = line
    
    return '\n'.join(result)


def fix_typescript_types(inputs: Dict[str, Any]) -> str:
    """
    Fix common TypeScript type issues in generated code.
    
    Inputs:
        content: TypeScript file content
    """
    content = inputs.get('content', inputs.get('default', ''))
    
    # Fix union types with undefined
    content = re.sub(r'\|\s*undefined\s*\|\s*null', ' | null', content)
    content = re.sub(r':\s*undefined\s*;', ': unknown;', content)
    
    # Fix array type syntax
    content = re.sub(r'Array<\s*([^>]+)\s*>', r'\1[]', content)
    
    # Fix optional property syntax
    content = re.sub(r'(\w+)\s*:\s*([^;]+)\s*\|\s*undefined\s*;', r'\1?: \2;', content)
    
    # Fix literal union types - this is the issue from the models.py
    # Convert ("a" | "b" | "c")[] to ("a" | "b" | "c")[]
    literal_pattern = r'\((["\'][^"\']+["\'](?:\s*\|\s*["\'][^"\']+["\']*)*)\)\[\]'
    
    def fix_literal_unions(match):
        literals = match.group(1)
        # Clean up the literals
        clean_literals = re.sub(r'["\']', '"', literals)
        return f'({clean_literals})[]'
    
    content = re.sub(literal_pattern, fix_literal_unions, content)
    
    return content


def format_python_docstrings(inputs: Dict[str, Any]) -> str:
    """
    Format Python docstrings to follow Google style.
    
    Inputs:
        content: Python file content
    """
    content = inputs.get('content', inputs.get('default', ''))
    
    # Simple docstring formatting
    # This is a basic implementation - a real one would use AST parsing
    
    # Fix triple quotes spacing
    content = re.sub(r'"""(\S)', r'"""\n    \1', content)
    content = re.sub(r'(\S)"""', r'\1\n    """', content)
    
    # Ensure proper indentation for docstrings
    lines = content.split('\n')
    result = []
    in_docstring = False
    indent_level = 0
    
    for line in lines:
        if '"""' in line:
            if not in_docstring:
                # Starting a docstring
                in_docstring = True
                # Determine indentation level
                indent_level = len(line) - len(line.lstrip())
            else:
                # Ending a docstring
                in_docstring = False
        
        if in_docstring and line.strip() and '"""' not in line:
            # Ensure proper indentation inside docstring
            stripped = line.strip()
            line = ' ' * (indent_level + 4) + stripped
        
        result.append(line)
    
    return '\n'.join(result)