#!/usr/bin/env python3
"""
Generate Strawberry GraphQL types from domain-schema.graphql.
This eliminates manual type definitions in the server.
"""

import re
from typing import Dict, List, Set, Tuple, Any
from pathlib import Path


def parse_graphql_schema(schema_content: str) -> Dict[str, Any]:
    """Parse GraphQL SDL schema into structured data."""
    
    # Parse scalars
    scalars = []
    scalar_pattern = r'"""([^"]+)"""\s*scalar\s+(\w+)'
    for match in re.finditer(scalar_pattern, schema_content):
        description, name = match.groups()
        scalars.append({
            'name': name,
            'description': description.strip()
        })
    
    # Parse enums
    enums = []
    enum_pattern = r'enum\s+(\w+)\s*\{([^}]+)\}'
    for match in re.finditer(enum_pattern, schema_content):
        name, values = match.groups()
        enum_values = [v.strip() for v in values.strip().split('\n') if v.strip()]
        enums.append({
            'name': name,
            'values': enum_values
        })
    
    # Parse types (including complex types with fields)
    types = []
    type_pattern = r'type\s+(\w+)\s*\{([^}]+)\}'
    for match in re.finditer(type_pattern, schema_content):
        name, fields_str = match.groups()
        fields = parse_fields(fields_str)
        types.append({
            'name': name,
            'fields': fields
        })
    
    # Parse input types
    input_types = []
    input_pattern = r'input\s+(\w+)\s*\{([^}]+)\}'
    for match in re.finditer(input_pattern, schema_content):
        name, fields_str = match.groups()
        fields = parse_fields(fields_str)
        input_types.append({
            'name': name,
            'fields': fields
        })
    
    # Parse unions
    unions = []
    union_pattern = r'union\s+(\w+)\s*=\s*([^\n]+)'
    for match in re.finditer(union_pattern, schema_content):
        name, types_str = match.groups()
        union_types = [t.strip() for t in types_str.split('|')]
        unions.append({
            'name': name,
            'types': union_types
        })
    
    return {
        'scalars': scalars,
        'enums': enums,
        'types': types,
        'input_types': input_types,
        'unions': unions
    }


def parse_fields(fields_str: str) -> List[Dict[str, Any]]:
    """Parse GraphQL fields from a type definition."""
    fields = []
    # Updated field parser - handles default values
    field_pattern = r'(\w+):\s*([^!\n=]+)(!?)(?:\s*=\s*(\w+))?'
    
    for line in fields_str.strip().split('\n'):
        line = line.strip()
        if not line or line.startswith('#'):
            continue
            
        match = re.match(field_pattern, line)
        if match:
            name, type_str, required, default_value = match.groups()
            # Clean up the type string
            type_str = type_str.strip()
            
            # If there's a default value, the field is optional
            has_default = default_value is not None
            
            fields.append({
                'name': name,
                'type': type_str,
                'required': bool(required) and not has_default,
                'is_list': '[' in type_str and ']' in type_str,
                'has_default': has_default,
                'default_value': default_value
            })
    
    return fields


def generate_strawberry_types(schema_data: Dict[str, Any]) -> str:
    """Generate Strawberry type definitions from parsed schema."""
    lines = []
    
    # Header
    lines.extend([
        '"""',
        'Auto-generated Strawberry GraphQL types from domain-schema.graphql.',
        'DO NOT EDIT MANUALLY - Generated by DiPeO codegen.',
        '"""',
        '',
        'from datetime import datetime',
        'from typing import NewType, Optional, List, Union, Any',
        '',
        'import strawberry',
        'from strawberry.scalars import JSON',
        '',
        '# Import domain models for Pydantic integration',
        'from dipeo.diagram_generated.domain_models import (',
        '    # Import all domain models that have Pydantic definitions',
        '    Vec2, TokenUsage, NodeState, DomainHandle, DiagramMetadata,',
        '    DomainNode, DomainArrow, PersonLLMConfig, DomainPerson,',
        '    DomainApiKey, DomainDiagram, ExecutionState, ExecutionOptions,',
        '    InteractivePromptData, InteractiveResponse, NodeDefinition,',
        '    Message, ConversationMetadata, Conversation,',
        '    # Import other types',
        '    MemorySettings, ToolConfig, WebSearchResult,',
        '    ImageGenerationResult, ToolOutput, ChatResult,',
        '    LLMRequestOptions',
        ')',
        '',
        '# Import node data types from individual model files',
        'from dipeo.diagram_generated.models.start_model import StartNodeData',
        'from dipeo.diagram_generated.models.condition_model import ConditionNodeData',
        'from dipeo.diagram_generated.models.person_job_model import PersonJobNodeData',
        'from dipeo.diagram_generated.models.code_job_model import CodeJobNodeData',
        'from dipeo.diagram_generated.models.api_job_model import ApiJobNodeData',
        'from dipeo.diagram_generated.models.endpoint_model import EndpointNodeData',
        'from dipeo.diagram_generated.models.db_model import DbNodeData',
        'from dipeo.diagram_generated.models.user_response_model import UserResponseNodeData',
        'from dipeo.diagram_generated.models.notion_model import NotionNodeData',
        'from dipeo.diagram_generated.models.hook_model import HookNodeData',
        'from dipeo.diagram_generated.models.template_job_model import TemplateJobNodeData',
        'from dipeo.diagram_generated.models.json_schema_validator_model import JsonSchemaValidatorNodeData',
        'from dipeo.diagram_generated.models.typescript_ast_model import TypescriptAstNodeData',
        'from dipeo.diagram_generated.models.sub_diagram_model import SubDiagramNodeData',
        'from dipeo.diagram_generated.models.person_batch_job_model import PersonBatchJobNodeData',
        '',
        '# Import all enums from separate module',
        'from dipeo.diagram_generated.enums import (',
        '    NodeType, HandleDirection, HandleLabel, DataType, MemoryView,',
        '    DiagramFormat, DBBlockSubType, ContentType, SupportedLanguage,',
        '    HttpMethod, HookType, HookTriggerMode, ExecutionStatus,',
        '    NodeExecutionStatus, EventType, LLMService, APIServiceType,',
        '    NotionOperation, ToolType',
        ')',
        '',
        ''
    ])
    
    # Generate scalars
    lines.append('# ============ Scalars ============')
    lines.append('')
    for scalar in schema_data['scalars']:
        if scalar['name'] == 'JSONScalar':
            # Special handling for JSONScalar
            lines.extend([
                'JSONScalar = strawberry.scalar(',
                '    NewType("JSONScalar", object),',
                '    name="JSONScalar",',
                '    description="Arbitrary JSON data",',
                '    serialize=lambda v: v,',
                '    parse_value=lambda v: v,',
                ')',
                ''
            ])
        else:
            # Regular scalar handling
            lines.extend([
                f'{scalar["name"]} = strawberry.scalar(',
                f'    NewType("{scalar["name"]}", str),',
                f'    description="{scalar["description"]}",',
                f'    serialize=lambda v: str(v),',
                f'    parse_value=lambda v: str(v) if v else None,',
                ')',
                ''
            ])
    
    lines.append('')
    
    # Generate enum registrations
    lines.append('# ============ Enum Registrations ============')
    lines.append('')
    for enum in schema_data['enums']:
        lines.append(f'{enum["name"]}Enum = strawberry.enum({enum["name"]})')
    lines.append('')
    lines.append('')
    
    # Track which types need Pydantic conversion
    pydantic_types = {
        'Vec2', 'TokenUsage', 'NodeState', 'DomainHandle', 'DiagramMetadata',
        'DomainNode', 'DomainArrow', 'PersonLLMConfig', 'DomainPerson',
        'DomainApiKey', 'DomainDiagram', 'ExecutionState', 'ExecutionOptions',
        'InteractivePromptData', 'InteractiveResponse', 'NodeDefinition',
        'Message', 'ConversationMetadata', 'Conversation',
        'StartNodeData', 'ConditionNodeData', 'PersonJobNodeData',
        'CodeJobNodeData', 'ApiJobNodeData', 'EndpointNodeData',
        'DbNodeData', 'UserResponseNodeData', 'NotionNodeData',
        'HookNodeData', 'TemplateJobNodeData', 'JsonSchemaValidatorNodeData',
        'TypescriptAstNodeData', 'SubDiagramNodeData', 'PersonBatchJobNodeData',
        'MemorySettings', 'ToolConfig', 'WebSearchResult',
        'ImageGenerationResult', 'ToolOutput', 'ChatResult',
        'LLMRequestOptions'
    }
    
    # Types that need custom field handling
    custom_field_types = {
        'DomainHandle': ['id', 'node_id'],
        'DomainNode': ['id', 'data'],
        'DomainArrow': ['id', 'source', 'target', 'data'],
        'DomainPerson': ['id'],
        'DomainApiKey': ['id'],
        'DomainDiagram': []
    }
    
    # Generate Pydantic-based types
    lines.append('# ============ Pydantic-based Types ============')
    lines.append('')
    
    for type_def in schema_data['types']:
        type_name = type_def['name']
        
        # Check if this is a Pydantic-based type
        base_name = type_name.replace('Type', '')
        
        # Handle special case mapping
        pydantic_base_name = base_name
        if base_name == 'DBNodeData':
            pydantic_base_name = 'DbNodeData'
            
        if base_name in pydantic_types or pydantic_base_name in pydantic_types:
            # Generate Pydantic wrapper
            lines.append(f'@strawberry.experimental.pydantic.type(')
            lines.append(f'    {pydantic_base_name},')
            
            # Determine which fields to include
            if base_name in custom_field_types:
                # Has custom fields - specify included fields
                included_fields = [
                    f['name'] for f in type_def['fields'] 
                    if f['name'] not in custom_field_types[base_name]
                ]
                if included_fields:
                    fields_str = ', '.join(f'"{f}"' for f in included_fields)
                    lines.append(f'    fields=[{fields_str}]')
                else:
                    lines.append('    all_fields=True')
            else:
                lines.append('    all_fields=True')
            
            lines.append(')')
            lines.append(f'class {type_name}Type:')
            
            # Add custom field resolvers
            if base_name in custom_field_types:
                for field_name in custom_field_types[base_name]:
                    field = next((f for f in type_def['fields'] if f['name'] == field_name), None)
                    if field:
                        # Determine return type
                        if field_name == 'id':
                            id_type = get_id_type_for_model(base_name)
                            lines.append(f'    @strawberry.field')
                            lines.append(f'    def {field_name}(self) -> {id_type}:')
                            lines.append(f'        obj = self._pydantic_object if hasattr(self, "_pydantic_object") else self')
                            lines.append(f'        return {id_type}(str(obj.{field_name}))')
                        elif field_name in ['node_id', 'source', 'target']:
                            # These are handle/node references
                            ref_type = 'HandleID' if field_name in ['source', 'target'] else 'NodeID'
                            lines.append(f'    @strawberry.field')
                            lines.append(f'    def {field_name}(self) -> {ref_type}:')
                            lines.append(f'        obj = self._pydantic_object if hasattr(self, "_pydantic_object") else self')
                            lines.append(f'        return {ref_type}(str(obj.{field_name}))')
                        elif field_name == 'data':
                            # JSON data field
                            optional = 'Optional[JSONScalar]' if base_name == 'DomainArrow' else 'JSONScalar'
                            lines.append(f'    @strawberry.field')
                            lines.append(f'    def {field_name}(self) -> {optional}:')
                            lines.append(f'        if hasattr(self, "_pydantic_object") and self._pydantic_object:')
                            if base_name == 'DomainArrow':
                                lines.append(f'            return self._pydantic_object.{field_name}')
                            else:
                                lines.append(f'            return self._pydantic_object.{field_name} or {{}}')
                            lines.append(f'        return getattr(self, "{field_name}", {{}})' if base_name != 'DomainArrow' else f'        return getattr(self, "{field_name}", None)')
                        lines.append('')
            
            # Add any additional computed fields
            if base_name == 'DomainDiagram':
                lines.append('    @strawberry.field')
                lines.append('    def nodeCount(self) -> int:')
                lines.append('        obj = self._pydantic_object if hasattr(self, "_pydantic_object") else self')
                lines.append('        return len(obj.nodes) if obj and hasattr(obj, "nodes") else 0')
                lines.append('')
                lines.append('    @strawberry.field')
                lines.append('    def arrowCount(self) -> int:')
                lines.append('        obj = self._pydantic_object if hasattr(self, "_pydantic_object") else self')
                lines.append('        return len(obj.arrows) if obj and hasattr(obj, "arrows") else 0')
            
            if not custom_field_types.get(base_name) and base_name != 'DomainDiagram':
                lines.append('    pass')
                
            lines.append('')
        else:
            # Regular Strawberry type (not Pydantic-based)
            lines.append(f'@strawberry.type')
            lines.append(f'class {type_name}:')
            for field in type_def['fields']:
                field_type = convert_graphql_type_to_python(field['type'], field['required'])
                lines.append(f'    {field["name"]}: {field_type}')
            lines.append('')
    
    # Generate input types
    if schema_data['input_types']:
        lines.append('')
        lines.append('# ============ Input Types ============')
        lines.append('')
        
        for input_type in schema_data['input_types']:
            lines.append(f'@strawberry.input')
            lines.append(f'class {input_type["name"]}:')
            for field in input_type['fields']:
                field_type = convert_graphql_type_to_python(field['type'], field['required'])
                # Handle default values for optional fields
                if not field['required'] and '=' not in field_type:
                    lines.append(f'    {field["name"]}: {field_type} = None')
                else:
                    lines.append(f'    {field["name"]}: {field_type}')
            lines.append('')
    
    # Generate unions
    if schema_data['unions']:
        lines.append('')
        lines.append('# ============ Unions ============')
        lines.append('')
        
        for union in schema_data['unions']:
            # Convert type names to their Strawberry type equivalents
            union_type_names = []
            for type_name in union['types']:
                # Special cases: These are regular strawberry types without "Type" suffix
                if type_name in ['BaseNodeData', 'TypescriptAstNodeData']:
                    union_type_names.append(type_name)
                # Add Type suffix if not already present
                elif not type_name.endswith('Type'):
                    union_type_names.append(f'{type_name}Type')
                else:
                    union_type_names.append(type_name)
            
            lines.append(f'{union["name"]} = strawberry.union("{union["name"]}", types=[{", ".join(union_type_names)}])')
            lines.append('')
    
    return '\n'.join(lines)


def get_id_type_for_model(model_name: str) -> str:
    """Get the appropriate ID type for a domain model."""
    id_mapping = {
        'DomainNode': 'NodeID',
        'DomainHandle': 'HandleID',
        'DomainArrow': 'ArrowID',
        'DomainPerson': 'PersonID',
        'DomainApiKey': 'ApiKeyID',
    }
    return id_mapping.get(model_name, 'str')


def convert_graphql_type_to_python(graphql_type: str, required: bool) -> str:
    """Convert GraphQL type notation to Python type hints."""
    # Remove whitespace
    graphql_type = graphql_type.strip()
    
    # Handle list types
    is_list = False
    if graphql_type.startswith('[') and graphql_type.endswith(']'):
        is_list = True
        graphql_type = graphql_type[1:-1].strip()
        # Remove trailing ! from list item type
        if graphql_type.endswith('!'):
            graphql_type = graphql_type[:-1]
    
    # Map GraphQL types to Python
    type_mapping = {
        'String': 'str',
        'Int': 'int',
        'Float': 'float',
        'Boolean': 'bool',
        'ID': 'str',
        'JSONScalar': 'JSONScalar',
    }
    
    # Check if it's a known scalar
    scalar_types = {
        'NodeID', 'HandleID', 'ArrowID', 'PersonID', 'ApiKeyID',
        'DiagramID', 'ExecutionID', 'HookID', 'TaskID'
    }
    
    # Check if it's a known enum
    enum_types = {
        'NodeType', 'HandleDirection', 'HandleLabel', 'DataType', 'MemoryView',
        'DiagramFormat', 'DBBlockSubType', 'ContentType', 'SupportedLanguage',
        'HttpMethod', 'HookType', 'HookTriggerMode', 'ExecutionStatus',
        'NodeExecutionStatus', 'EventType', 'LLMService', 'APIServiceType',
        'NotionOperation', 'ToolType'
    }
    
    if graphql_type in type_mapping:
        python_type = type_mapping[graphql_type]
    elif graphql_type in scalar_types:
        python_type = graphql_type
    elif graphql_type in enum_types:
        python_type = graphql_type
    else:
        # Assume it's a custom type (add Type suffix if needed)
        python_type = graphql_type if graphql_type.endswith('Type') else f'{graphql_type}Type'
    
    # Apply list wrapper
    if is_list:
        python_type = f'List[{python_type}]'
    
    # Apply optional wrapper
    if not required and not is_list:
        python_type = f'Optional[{python_type}]'
    
    return python_type


def main(inputs: dict) -> dict:
    """Main entry point for DiPeO diagram execution."""
    # Get the GraphQL schema content
    schema_content = inputs.get('schema_content', '')
    
    if not schema_content:
        return {'error': 'No schema content provided'}
    
    # Parse the schema
    schema_data = parse_graphql_schema(schema_content)
    
    # Generate Strawberry types
    generated_code = generate_strawberry_types(schema_data)
    
    # Return both the generated code and metadata
    return {
        'generated_code': generated_code,
        'metadata': {
            'scalars_count': len(schema_data['scalars']),
            'enums_count': len(schema_data['enums']),
            'types_count': len(schema_data['types']),
            'input_types_count': len(schema_data['input_types']),
            'unions_count': len(schema_data['unions'])
        }
    }