version: light
nodes:
- label: Start
  type: start
  position: {x: -728, y: 348}
  props:
    trigger_mode: manual
- label: Load Raw Data
  type: db
  position: {x: -386, y: 146}
  props:
    operation: read
    sub_type: file
    source_details: files/uploads/raw_data.csv
- label: Load Config
  type: db
  position: {x: -413, y: 481}
  props:
    flipped: [false, true]
    operation: read
    sub_type: file
    source_details: files/config/processing_rules.json
- label: Parse Data
  type: code_job
  position: {x: 19, y: 342}
  props:
    code: |
      import json
      import csv
      from io import StringIO

      # Parse CSV data
      csv_reader = csv.DictReader(StringIO(raw_data))
      data_rows = list(csv_reader)

      # Parse config
      config = json.loads(config_data)

      # Basic validation
      total_rows = len(data_rows)
      valid_rows = [row for row in data_rows if all(row.values())]
      invalid_rows = total_rows - len(valid_rows)

      # Prepare data for quality check
      data_summary = {
          "total_rows": total_rows,
          "valid_rows": len(valid_rows),
          "invalid_rows": invalid_rows,
          "columns": list(data_rows[0].keys()) if data_rows else [],
          "sample_data": data_rows[:5] if data_rows else []
      }

      print(f"Parsed {total_rows} rows, {invalid_rows} invalid")
    code_type: python
- label: Quality Check
  type: person_job
  position: {x: 355, y: 233}
  props:
    default_prompt: |
      Analyze this data summary and provide a quality score (0-100):
      {{data_summary}}

      Return only a JSON object with: {"score": <number>, "issues": [<list of issues>]}
    max_iteration: 1
    person: QualityChecker
- label: Extract Score
  type: code_job
  position: {x: 731, y: 425}
  props:
    code: |
      import json
      quality_result = json.loads(quality_check_output)
      quality_score = quality_result.get("score", 0)
      quality_issues = quality_result.get("issues", [])

      # Also store in data_rows and config for later use
      data_rows = data_rows if 'data_rows' in locals() else []
      config = config if 'config' in locals() else {}

      print(f"Quality score: {quality_score}")
      print(f"Issues found: {len(quality_issues)}")
    code_type: python
- label: Check Quality Threshold
  type: condition
  position: {x: 720, y: 775}
  props:
    condition_type: custom
    expression: quality_score >= 70
    flipped: [true, false]
- label: Transform Data
  type: person_job
  position: {x: 271, y: 943}
  props:
    default_prompt: |
      Transform this data according to the rules:
      Data: {{data_rows}}
      Rules: {{config}}

      Apply all transformations and return clean JSON data.
    flipped: [true, false]
    max_iteration: 1
    memory_profile: MINIMAL
    person: Transformer
- label: Enrich with API
  type: api_job
  position: {x: -79, y: 995}
  props:
    flipped: [true, false]
    headers:
      Accept: application/json
    method: GET
    url: https://api.exchangerate-api.com/v4/latest/USD
- label: Merge Enriched Data
  type: code_job
  position: {x: -393, y: 854}
  props:
    code: |
      import json

      # Parse transformed data
      transformed = json.loads(transformed_data)

      # Parse API response
      api_data = json.loads(api_response)
      exchange_rates = api_data.get("rates", {})

      # Enrich data with exchange rates
      enriched_data = []
      for item in transformed:
          if "amount_usd" in item:
              item["amount_eur"] = item["amount_usd"] * exchange_rates.get("EUR", 0.85)
              item["amount_gbp"] = item["amount_usd"] * exchange_rates.get("GBP", 0.73)
          enriched_data.append(item)

      result = {
          "processed_at": api_data.get("date", "unknown"),
          "total_records": len(enriched_data),
          "data": enriched_data
      }
    flipped: [true, false]
    code_type: python
- label: Analyze Patterns
  type: person_job
  position: {x: -722, y: 1054}
  props:
    default_prompt: |
      Analyze these patterns in the enriched data:
      {{result}}

      Provide insights on:
      1. Key trends
      2. Anomalies
      3. Recommendations

      Format as JSON with sections for each.
    flipped: [true, false]
    max_iteration: 1
    memory_profile: FOCUSED
    person: DataAnalyst
- label: Handle Low Quality
  type: code_job
  position: {x: 276, y: 655}
  props:
    code: |
      error_report = {
          "status": "failed",
          "reason": "Data quality below threshold",
          "quality_score": quality_score,
          "issues": quality_issues,
          "recommendation": "Please clean the source data and retry"
      }

      print("Processing failed due to low data quality")
    flipped: [true, false]
    code_type: python
- label: Generate Report
  type: person_job
  position: {x: -1040, y: 836}
  props:
    default_prompt: |
      Create a comprehensive data processing report combining:
      - Processing summary: {{result}}
      - Pattern analysis: {{analysis}}
      - Quality metrics: Score {{quality_score}}

      Format as a professional markdown report with sections, tables, and recommendations.
    flipped: [true, false]
    max_iteration: 1
    memory_profile: FULL
    person: ReportWriter
- label: Save Success Report
  type: endpoint
  position: {x: -1305, y: 657}
  props:
    file_format: md
    save_to_file: true
    file_path: files/results/data_processing_report.md
- label: Save Processed Data
  type: endpoint
  position: {x: -869, y: 638}
  props:
    file_format: json
    save_to_file: true
    file_path: files/results/processed_data.json
- label: Save Error Report
  type: endpoint
  position: {x: -102, y: 600}
  props:
    file_format: json
    save_to_file: true
    file_path: files/results/error_report.json
connections:
- from: Start
  to: Load Raw Data
  content_type: raw_text
- from: Start
  to: Load Config
  content_type: raw_text
- from: Load Raw Data
  to: Parse Data
  content_type: raw_text
  label: raw_data
- from: Load Config
  to: Parse Data
  content_type: raw_text
  label: config_data
- from: Parse Data
  to: Quality Check
  content_type: variable
- from: Quality Check
  to: Extract Score
  content_type: raw_text
  label: quality_check_output
- from: Extract Score
  to: Check Quality Threshold
  content_type: variable
- from: Check Quality Threshold_condtrue
  to: Transform Data
  content_type: variable
- from: Transform Data
  to: Enrich with API
  content_type: raw_text
  label: transformed_data
- from: Enrich with API
  to: Merge Enriched Data
  content_type: raw_text
  label: api_response
- from: Merge Enriched Data
  to: Analyze Patterns
  content_type: variable
- from: Analyze Patterns
  to: Generate Report
  content_type: raw_text
  label: analysis
- from: Merge Enriched Data
  to: Generate Report
  content_type: variable
- from: Generate Report
  to: Save Success Report
  content_type: raw_text
- from: Merge Enriched Data
  to: Save Processed Data
  content_type: variable
- from: Check Quality Threshold_condfalse
  to: Handle Low Quality
  content_type: variable
- from: Handle Low Quality
  to: Save Error Report
  content_type: variable
persons:
  DataAnalyst:
    service: openai
    model: gpt-4.1-nano
    system_prompt: You are a data analyst expert. Analyze data patterns and provide
      insights in JSON format.
    api_key_id: APIKEY_52609F
  QualityChecker:
    service: openai
    model: gpt-4.1-nano
    system_prompt: You are a data quality expert. Check for data integrity issues
      and return a score from 0-100.
    api_key_id: APIKEY_52609F
  ReportWriter:
    service: openai
    model: gpt-4.1-nano
    system_prompt: You write comprehensive data analysis reports in markdown format.
    api_key_id: APIKEY_52609F
  Transformer:
    service: openai
    model: gpt-4.1-nano
    system_prompt: You transform data according to business rules. Output clean, structured
      data.
    api_key_id: APIKEY_52609F
