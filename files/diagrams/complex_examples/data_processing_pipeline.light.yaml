version: light

persons:
  DataAnalyst:
    service: openai
    model: gpt-4.1-nano
    system_prompt: You are a data analyst expert. Analyze data patterns and provide insights in JSON format.
    api_key_id: APIKEY_52609F
  
  QualityChecker:
    service: openai
    model: gpt-4.1-nano
    system_prompt: You are a data quality expert. Check for data integrity issues and return a score from 0-100.
    api_key_id: APIKEY_52609F
  
  Transformer:
    service: openai
    model: gpt-4.1-nano
    system_prompt: You transform data according to business rules. Output clean, structured data.
    api_key_id: APIKEY_52609F
  
  ReportWriter:
    service: openai
    model: gpt-4.1-nano
    system_prompt: You write comprehensive data analysis reports in markdown format.
    api_key_id: APIKEY_52609F

nodes:
  - label: Start
    type: start
    position: {x: 50, y: 300}
    props:
      trigger_mode: manual

  - label: Load Raw Data
    type: db
    position: {x: 200, y: 200}
    props:
      operation: read
      sub_type: file
      source_details: files/uploads/raw_data.csv

  - label: Load Config
    type: db
    position: {x: 200, y: 400}
    props:
      operation: read
      sub_type: file
      source_details: files/config/processing_rules.json

  - label: Parse Data
    type: code_job
    position: {x: 400, y: 300}
    props:
      code_type: python
      code: |
        import json
        import csv
        from io import StringIO
        
        # Parse CSV data
        csv_reader = csv.DictReader(StringIO(raw_data))
        data_rows = list(csv_reader)
        
        # Parse config
        config = json.loads(config_data)
        
        # Basic validation
        total_rows = len(data_rows)
        valid_rows = [row for row in data_rows if all(row.values())]
        invalid_rows = total_rows - len(valid_rows)
        
        # Prepare data for quality check
        data_summary = {
            "total_rows": total_rows,
            "valid_rows": len(valid_rows),
            "invalid_rows": invalid_rows,
            "columns": list(data_rows[0].keys()) if data_rows else [],
            "sample_data": data_rows[:5] if data_rows else []
        }
        
        print(f"Parsed {total_rows} rows, {invalid_rows} invalid")

  - label: Quality Check
    type: person_job
    position: {x: 600, y: 200}
    props:
      person: QualityChecker
      default_prompt: |
        Analyze this data summary and provide a quality score (0-100):
        {{data_summary}}
        
        Return only a JSON object with: {"score": <number>, "issues": [<list of issues>]}
      max_iteration: 1

  - label: Extract Score
    type: code_job
    position: {x: 800, y: 200}
    props:
      code_type: python
      code: |
        import json
        quality_result = json.loads(quality_check_output)
        quality_score = quality_result.get("score", 0)
        quality_issues = quality_result.get("issues", [])
        
        # Also store in data_rows and config for later use
        data_rows = data_rows if 'data_rows' in locals() else []
        config = config if 'config' in locals() else {}
        
        print(f"Quality score: {quality_score}")
        print(f"Issues found: {len(quality_issues)}")

  - label: Check Quality Threshold
    type: condition
    position: {x: 1000, y: 300}
    props:
      condition_type: custom
      expression: quality_score >= 70
      flipped: false

  - label: Transform Data
    type: person_job
    position: {x: 1200, y: 200}
    props:
      person: Transformer
      default_prompt: |
        Transform this data according to the rules:
        Data: {{data_rows}}
        Rules: {{config}}
        
        Apply all transformations and return clean JSON data.
      max_iteration: 1
      memory_profile: MINIMAL

  - label: Enrich with API
    type: api_job
    position: {x: 1400, y: 200}
    props:
      url: https://api.exchangerate-api.com/v4/latest/USD
      method: GET
      headers:
        Accept: application/json

  - label: Merge Enriched Data
    type: code_job
    position: {x: 1600, y: 200}
    props:
      code_type: python
      code: |
        import json
        
        # Parse transformed data
        transformed = json.loads(transformed_data)
        
        # Parse API response
        api_data = json.loads(api_response)
        exchange_rates = api_data.get("rates", {})
        
        # Enrich data with exchange rates
        enriched_data = []
        for item in transformed:
            if "amount_usd" in item:
                item["amount_eur"] = item["amount_usd"] * exchange_rates.get("EUR", 0.85)
                item["amount_gbp"] = item["amount_usd"] * exchange_rates.get("GBP", 0.73)
            enriched_data.append(item)
        
        result = {
            "processed_at": api_data.get("date", "unknown"),
            "total_records": len(enriched_data),
            "data": enriched_data
        }

  - label: Analyze Patterns
    type: person_job
    position: {x: 1600, y: 400}
    props:
      person: DataAnalyst
      default_prompt: |
        Analyze these patterns in the enriched data:
        {{result}}
        
        Provide insights on:
        1. Key trends
        2. Anomalies
        3. Recommendations
        
        Format as JSON with sections for each.
      max_iteration: 1
      memory_profile: FOCUSED

  - label: Handle Low Quality
    type: code_job
    position: {x: 1000, y: 500}
    props:
      code_type: python
      code: |
        error_report = {
            "status": "failed",
            "reason": "Data quality below threshold",
            "quality_score": quality_score,
            "issues": quality_issues,
            "recommendation": "Please clean the source data and retry"
        }
        
        print("Processing failed due to low data quality")

  - label: Generate Report
    type: person_job
    position: {x: 1800, y: 300}
    props:
      person: ReportWriter
      default_prompt: |
        Create a comprehensive data processing report combining:
        - Processing summary: {{result}}
        - Pattern analysis: {{analysis}}
        - Quality metrics: Score {{quality_score}}
        
        Format as a professional markdown report with sections, tables, and recommendations.
      max_iteration: 1
      memory_profile: FULL

  - label: Save Success Report
    type: endpoint
    position: {x: 2000, y: 200}
    props:
      file_format: md
      save_to_file: true
      file_path: files/results/data_processing_report.md

  - label: Save Processed Data
    type: endpoint
    position: {x: 2000, y: 400}
    props:
      file_format: json
      save_to_file: true
      file_path: files/results/processed_data.json

  - label: Save Error Report
    type: endpoint
    position: {x: 1200, y: 500}
    props:
      file_format: json
      save_to_file: true
      file_path: files/results/error_report.json

connections:
  - from: Start
    to: Load Raw Data
  
  - from: Start
    to: Load Config
  
  - from: Load Raw Data
    to: Parse Data
    label: raw_data
  
  - from: Load Config
    to: Parse Data
    label: config_data
  
  - from: Parse Data
    to: Quality Check
    content_type: variable
  
  - from: Quality Check
    to: Extract Score
    label: quality_check_output
  
  - from: Extract Score
    to: Check Quality Threshold
    content_type: variable
  
  - from: Check Quality Threshold_condtrue
    to: Transform Data
    content_type: variable
  
  - from: Transform Data
    to: Enrich with API
    label: transformed_data
  
  - from: Enrich with API
    to: Merge Enriched Data
    label: api_response
  
  - from: Merge Enriched Data
    to: Analyze Patterns
    content_type: variable
  
  - from: Analyze Patterns
    to: Generate Report
    label: analysis
  
  - from: Merge Enriched Data
    to: Generate Report
    content_type: variable
  
  - from: Generate Report
    to: Save Success Report
    content_type: raw_text
  
  - from: Merge Enriched Data
    to: Save Processed Data
    content_type: variable
  
  - from: Check Quality Threshold_condfalse
    to: Handle Low Quality
    content_type: variable
  
  - from: Handle Low Quality
    to: Save Error Report
    content_type: variable